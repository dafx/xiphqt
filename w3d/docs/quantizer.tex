
\section{ Quantizing, Merging the Bitstreams }

The relevant code is in \verb|wavelet_coeff.c|.

Wavelet coefficients are scanned linear in each quadrant, in the 2D case like
this: $HL$ $LH$ $LL$, then $HL^1$ $LH^1$ $LL^1$ in $HH$ and so forth.
We don't quantize the coefficients explizitly but transmit
them bitplane-by-bitplane (significand and insignificand bits in different
bitstreams, thus two streams per bitplane). Signs get encoded in the bitstream
of the first significand bitplane.

All bitplanes are encoded in parallel, so we only need a single pass to
transmit all coefficients. Later the resulting bitstreams get entropy coded
(see section \ref{entropy}) and merged (see below).
When you don't transmit the entire bitstream you quantize and threshold the
coefficients implicitly by cutting away insignificand bits and small
coefficients.


\subsection { Merging the Bitstreams }

After Coefficient scanning and entropy coding we have a set of about 9 or 10
bitstreams. The function \verb|merge_bitstreams()| merges them into a single
stream which will be written to the file.
This is process is controlled by truncation tables which are created in
\verb|setup_limittabs()|. There we can easy play with different approaches to
cut+merge the bitstreams.

Currently each less significand bitstream gets about half as long as its 
next more significand bitstream. Significand bitstreams get $4/8$ of the
bit budget, insignificand ones the rest.
Another approach would be to try to give all streams equal lengths, this
would mean to transmit equal energies at all frequencies.

Unfortunally we have to transmit these tables in order to reconstruct the per
bitplane streams, this done using binary 32bit numbers for now. At low 
bitrates we quickly spend half of the bit budget on the truncation tables.
Since these tables contain mostly small numbers they should compress well 
and we should compress them.

